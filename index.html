<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gabriele Prato</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div id="profile_container"><img src="images/profile_with_alpha.png" alt="Profile Picture" id="profile_picture"></div>
    <div id="name">Gabriele Prato</div>
    <table id="links">
        <tr>
            <td id="email_td"><span id="email">gabriele.prato@mila.quebec</span></td>
            <td class="logo_td" id="cv_td">
                <a href="resume.pdf", title="Resume" id="cv_logo" class="logo">
                    <img src="images/cv_blue.png" alt="Curriculum Vitae" class="logo_nohover">
                    <img src="images/cv_lightblue.png" alt="Curriculum Vitae" class="logo_hover">
                </a>
            </td>
            <td class="logo_td" id="googlescholar_td">
                <a href="http://scholar.google.ca/citations?user=9D_y8ssAAAAJ&hl=en" title="Google Scholar" id="googlescholar_logo" class="logo">
                    <img src="images/googlescholar_blue.png" alt="Google Scholar" class="logo_nohover">
                    <img src="images/googlescholar_lightblue.png" alt="Google Scholar" class="logo_hover">
                </a>
            </td>
            <td class="logo_td" id="linkedin_td">
                <a href="https://www.linkedin.com/in/gabprato" title="LinkedIn" class="logo">
                    <img src="images/linkedin_blue.png" alt="LinkedIn" class="logo_nohover">
                    <img src="images/linkedin_lightblue.png" alt="LinkedIn" class="logo_hover">
                </a>
            </td>
            <td class="logo_td" id="github_td">
                <a href="https://github.com/gabprato", title="Github" id="github_logo" class="logo">
                    <img src="images/github_blue.png" alt="Github" class="logo_nohover">
                    <img src="images/github_lightblue.png" alt="Github" class="logo_hover">
                </a>
            </td>
            <td class="logo_td" id="twitter_td">
                <a href="https://twitter.com/GabrielePrato", title="Twitter" class="logo">
                    <img src="images/twitter_blue.png" alt="Twitter" class="logo_nohover">
                    <img src="images/twitter_lightblue.png" alt="Twitter" class="logo_hover">
                </a>
            </td>
        </tr>
    </table>
    <div id="about">I am a final-year PhD candidate at Mila, University of Montreal, anticipating graduation in the spring or summer of 2025. My research focuses on the fundamental aspects of Large Language Models (LLMs). Specifically, I have explored how data segmentation influences critical functions such as parametric knowledge retrieval and latent multi-hop reasoning.<br/><br/>In addition to investigating these foundational dynamics, my work also seeks to address the inherent limitations of LLMs. For instance, I aim to develop methods that allow these models to better consolidate their knowledge during training, enhancing their utility and impact.<br/><br/>I am deeply committed to advancing the field of machine learning through open-ended research and academic exploration. My goal is to produce impactful, publishable work that contributes meaningfully to the scientific community. I am seeking research-focused roles in industry that align with these values and support my passion for driving innovation.</div>
    <div id="hr-pub"><span id="hr-text">Publications</span></div>
    <div id="papers">
	<a href="https://arxiv.org/abs/2310.15372">
            <div class="paper">
            <span class="paper-name">EpiK-Eval: Evaluation for Language Models as Epistemic Models</span><br/>
            <span class="paper-conference">EMNLP 2023</span>
            </div>
        </a>
	<a href="https://arxiv.org/abs/2211.14449">
            <div class="paper">
            <span class="paper-name">PatchBlender: A Motion Prior for Video Transformers</span><br/>
            <span class="paper-conference">NeurIPS 2022 Workshop, Vision Transformers: Theory and Applications</span>
            </div>
        </a>
        <a href="https://arxiv.org/abs/2110.06990">
            <div class="paper">
            <span class="paper-name">Scaling Laws for the Few-Shot Adaptation of Pre-trained Image Classifiers</span><br/>
            <span class="paper-conference">ICML 2021 Workshop, Uncertainty & Robustness in Deep Learning</span>
            </div>
        </a>
        <a href="https://arxiv.org/abs/1910.10485">
            <div class="paper">
            <span class="paper-name">Fully Quantized Transformer for Machine Translation</span><br/>
            <span class="paper-conference">Findings of EMNLP 2020</span>
            </div>
        </a>
        <a href="https://arxiv.org/abs/1906.01659">
            <div class="paper">
            <span class="paper-name">Towards Lossless Encoding of Sentences</span><br/>
            <span class="paper-conference">ACL 2019</span>
            </div>
        </a>
    </div>
    <div id="hr-blog" class="blog-posts"><span id="hr-text">Blog Posts</span></div>
    <div id="papers">
    <a href="/epik-eval/">
            <div class="paper">
            <span class="paper-name">EpiK-Eval and the Role of Knowledge Consolidation in Language Models</span><br/>
            <span class="paper-conference">December 22, 2023</span>
            </div>
        </a>
    </div>
</body>
</html>
