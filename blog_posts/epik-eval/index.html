---
layout: blog_posts

permalink: /epik-eval/
---

<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EpiK-Eval</title>
    <link rel="stylesheet" href="/blog_posts/epik-eval/styles.css">
    <link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">
</head>

<body>
    <a href="/" class="profile-with-name">
        <img src="/images/profile_with_alpha.png" alt="Profile Picture" class="profile-picture">
        <div class="name-text">Gabriele Prato</div>
    </a>
    <hr id="hr-menu" />
    <div id="blog_post_name">EpiK-Eval and the Role of Knowledge Consolidation in Language Models</div>
    <table id="paper-links">
        <tr>
            <td class="paper-link-td paper-link-vert-bar"><a href="https://arxiv.org/abs/2310.15372" class="paper-link">Paper</a></td>
            <td class="paper-link-td paper-link-pad-left"><a href="https://github.com/chandar-lab/EpiK-Eval" class="paper-link">Code</a></td>
            <!-- <td class="paper-link-td paper-link-pad-left"><a href="" class="paper-link">Video</a></td> -->
        </tr>
    </table>
    <div id="blog_post">
        Large Language Models (LLMs) have dramatically transformed the landscape, heralding a significant shift in research focus and reshaping the industry at large. This transformative impact primarily stems from advancements in computational scale rather than methodological innovations. While scaling up has undeniably enhanced model performance, it is crucial to recognize that several challenges remain unaddressed by mere scale, including:
        <ul>
          <li>Alignment</li>
          <li>Continual Learning</li>
          <li>Context Length</li>
          <li>Hallucinations</li>
          <li>Computational Efficiency</li>
        </ul>
        In this post, we explore an additional issue potentially belonging to this list, one that has been overlooked despite its importance: knowledge consolidation.
        <br/>

        <a href="#knowledge-consolidation" class="section-link">
            <img src="/blog_posts/epik-eval/images/hyperlink_symbol.png" class="hyperlink-icon">
            <div id="knowledge-consolidation" class="section_title">Knowledge Consolidation</div>
        </a><br/>
        The training corpora of LLMs are immense, containing a myriad of facts, events, topics, concepts, ideas, and various pieces of knowledge. These elements can relate to one another in many different ways, forming a complex web of dependencies.
        <div id="slide7-container"><img id="slide7" src="/blog_posts/epik-eval/images/slide7.svg"/></div>
        However, LLMs do not inherently learn all these dependencies.
        <div id="slide8-container"><img id="slide8" src="/blog_posts/epik-eval/images/slide8.svg"/></div>
        This limitation stems from their training objectives. LLMs are trained to predict tokens based on the context within a given text sequence, utilizing the knowledge encoded in their training parameters.
        <div id="slide9-container"><img id="slide9" src="/blog_posts/epik-eval/images/slide9.svg"/></div>
        As a result, if the content of one training sample does not aid in predicting the content of another, the model receives no signal to establish a relationship between them. Consider the example of two news articles: one mentioning a celebrity's wedding in Miami in six months, and another, dated six months later, reporting a hurricane in Florida.
        <div id="slide10-container"><img id="slide10" src="/blog_posts/epik-eval/images/slide10.svg"/></div>
        Since the content of one article doesn't directly help in predicting the content of the other, the model does not learn to relate them. Therefore, during inference, the model wouldn't associate the hurricane with the potential impact on the wedding's logistics.
        <div id="slide11-container"><img id="slide11" src="/blog_posts/epik-eval/images/slide11.svg"/></div>
        This leads us to the crux of knowledge consolidation: the model is aware of both events (A and B), but it is unaware of the relationship between them.
        <div id="slide12-container"><img id="slide12" src="/blog_posts/epik-eval/images/slide12.svg"/></div>
        To overcome this, the model needs to consolidate its knowledge, learning to connect related but disparate pieces of information.
        <div id="slide13-container"><img id="slide13" src="/blog_posts/epik-eval/images/slide13.svg"/></div>

        <a href="#epik-eval-benchmark" class="section-link">
            <img src="/blog_posts/epik-eval/images/hyperlink_symbol.png" class="hyperlink-icon">
            <div id="epik-eval-benchmark" class="section_title">EpiK-Eval Benchmark</div>
        </a><br/>
        The <span class="in-text-paper-link-container"><a class="in-text-paper-link" href="https://arxiv.org/abs/2310.15372">EpiK-Eval</a></span> benchmark is key in revealing the knowledge consolidation challenge in LLMs. Our primary objective is to assess LLMs' ability to utilize information distributed across different training samples.
        </br></br>
        We begin by dividing stories into smaller passages.
        <div id="slide15-container"><img id="slide15" src="/blog_posts/epik-eval/images/slide15.svg"/></div>
        Next, we train one model on these unsegmented stories
        <div id="slide16top-container"><img id="slide16top" src="/blog_posts/epik-eval/images/slide16top.svg"/></div>
        and another on the segmented versions.
        <div id="slide16bot-container"><img id="slide16bot" src="/blog_posts/epik-eval/images/slide16bot.svg"/></div>
        The critical test involves querying the latter model with questions that requires synthesizing information from multiple story segments.
        <div id="slide17-18-container">
            <img id="slide17" src="/blog_posts/epik-eval/images/slide17.svg"/>
            <img id="slide18" src="/blog_posts/epik-eval/images/slide18.svg"/>
        </div>
        This approach allows us to compare its performance against the prior model trained on unsegmented stories. The comparison highlights the added challenge of processing information dispersed across various training samples as opposed to recalling it from a single source.
        <br/><br/>
        Unlike multi-hop question answering, our models rely exclusively on the information encoded in their parameters, without access to the original documents.
        <br/><br/>
        For practical reasons<a id="footnote-link1-practical-reasons" href="#footnote-practical-reasons" class="footnote-link1">1</a>, we use self-generated short stories, each only a few sentences long, and segment them by sentence. We train the models using standard pre-training objectives, such as causal or masked language modeling. Here's an illustrative example: a story about a person visiting a restaurant and ordering items.
        <div id="slide20top-container"><img id="slide20top" src="/blog_posts/epik-eval/images/slide20top.svg"/></div>
        <div id="slide20bot-container"><img id="slide20bot" src="/blog_posts/epik-eval/images/slide20bot.svg"/></div>
        In our question-answer format, the model first has to recall the entire story, testing its ability to consolidate and recall the learned segments. This is followed by a reasoning statement and a conclusive answer.
        <div id="slide21-container"><img id="slide21" src="/blog_posts/epik-eval/images/slide21.svg"/></div>
        To acclimate models to this format, we incorporate question-answer example pairs in the training dataset.
        <div id="footnote-practical-reasons" class="footnote"><a href="#footnote-link1-practical-reasons" class="footnote-link2">1.</a> Optimally, our intention is to segment extensive texts, including books; however, we face computational limitations that restrict our ability to do so.</div>

        <a href="#results" class="section-link">
            <img src="/blog_posts/epik-eval/images/hyperlink_symbol.png" class="hyperlink-icon">
            <div id="results" class="subsection_title">Results</div>
        </a><br/>
        Our findings reveal a significant disparity in performance between models trained on segmented stories and those trained on unsegmented stories. The following plot illustrates this difference: models trained on segmented stories (<span class="orange-text">orange</span>) underperform compared to those trained on unsegmented stories (<span class="blue-text">blue</span>), with the y-axis representing the percentage of correctly answered questions.
        <div id="slide19-container"><img id="slide19" src="/blog_posts/epik-eval/images/slide19.svg"/></div>
        Breaking down our analysis into the three components—recall, reasoning, and the final answer—yields the following insights. Firstly, we assess the accuracy of recall alone. Here, a notable performance gap is observed, favoring models trained on unsegmented stories.
        <div id="slide22-container"><img id="slide22" src="/blog_posts/epik-eval/images/slide22A.svg"/></div>
        Next, focusing on instances where recall is accurate, we evaluate the correctness of reasoning.
        <div id="slide22-container"><img id="slide22" src="/blog_posts/epik-eval/images/slide22B.svg"/></div>
        The results show similar performance levels between both setups. Although models trained on segmented stories exhibit marginally better reasoning, we attribute this to variance. This is because the subset of correctly recalled answers is smaller for models trained on segmented stories, as shown in the Recall plot. Thus, we do not infer any enhancement in reasoning capabilities from segmented story training.
        <br/><br/>
        Finally, we analyze the subset of answers where both recall and reasoning are correct, examining the accuracy of the final answer.
        <div id="slide22-container"><img id="slide22" src="/blog_posts/epik-eval/images/slide22C.svg"/></div>
        Once again, the performance is comparable between both setups, with the argument about variance remaining valid.
        <br/><br/>
        Overall, our results indicate that the primary challenge for models trained on segmented stories lies in accurately recalling and consolidating knowledge, unlike their unsegmented counterparts. Despite both setups showing perfect memorization of training samples—as evidenced by a near-zero hallucination rate<a id="footnote-link1-hallucination-rate-definition" href="#footnote-hallucination-rate-definition" class="footnote-link1">2</a> during training—
        <div id="slide22-container"><img id="slide22" src="/blog_posts/epik-eval/images/slide23A.svg"/></div>
        a different trend emerges during inference. Models trained on segmented stories exhibit a higher rate of hallucinations in their recall responses.
        <div id="slide22-container"><img id="slide22" src="/blog_posts/epik-eval/images/slide23B.svg"/></div>
        Interestingly, these models not only struggled with piecing together the story segments but also begin introducing hallucinations within sentences they had previously memorized flawlessly. This phenomenon occurs exclusively when tasked with reconstructing the entire story, not when recalling individual sentences.
        <div id="slide24-container"><img id="slide24" src="/blog_posts/epik-eval/images/slide24.svg"/></div>
        <div id="footnote-hallucination-rate-definition" class="footnote"><a href="#footnote-link1-hallucination-rate-definition" class="footnote-link2">2.</a> We define the hallucination rate as the number of recalled sentences that contain an error (does not match with the actual sentence in the narrative) over the total number of recalled sentences.</div>

        <a href="#implications-and-future-directions" class="section-link">
            <img src="/blog_posts/epik-eval/images/hyperlink_symbol.png" class="hyperlink-icon">
            <div id="implications-and-future-directions" class="section_title">Implications and Future Directions</div>
        </a><br/>
        A pertinent question arising from our study is whether scaling up models will address the challenge of knowledge consolidation. While we observe general performance improvement with increased scale in both segmented and unsegmented story training setups, a key indicator for scale resolving knowledge consolidation would be a disproportionately higher improvement rate in models trained on segmented stories.
        <div id="slide27-container"><img id="slide27" src="/blog_posts/epik-eval/images/slide27.svg"/></div>
        Though possible at larger scales, and certainly warranting further investigation with larger models, the inherent limitations of the training objectives – which do not explicitly encourage learning inter-sample dependencies – leads us to believe that scale alone may not suffice. However, it's worth considering that a sufficiently large and diverse training corpus might inadvertently cover essential dependencies, mitigating this issue in practice. This hypothesis requires deeper exploration.
        <br/><br/>
        Another query might be: why not employ retrieval tools to supplement model recall? While feasible, and already implemented in systems like ChatGPT, the fundamental challenge persists.
        <div id="slide29-container"><img id="slide29" src="/blog_posts/epik-eval/images/slide29.svg"/></div>
        In the long term, cutting-edge retrieval systems are likely to be AI-driven rather than manually engineered. Whether it's a language model or a retrieval system, the AI needs to comprehend and navigate the intricate web of relationships among diverse data types—topics, facts, books, news articles, blog posts, papers, etc. Given that the only ground truth are the documents themselves,
        <div id="slide30-container"><img id="slide30" src="/blog_posts/epik-eval/images/slide30.svg"/></div>
        and not the inter-document relationships, any system we deploy must autonomously learn and consolidate these relationships from the dataset.
        <div id="slide31-container"><img id="slide31" src="/blog_posts/epik-eval/images/slide31.svg"/></div>

        <a href="#conclusion" class="section-link">
            <img src="/blog_posts/epik-eval/images/hyperlink_symbol.png" class="hyperlink-icon">
            <div id="conclusion" class="section_title">Conclusion</div>
        </a><br/>
        Our study with the <span class="in-text-paper-link-container"><a class="in-text-paper-link" href="https://arxiv.org/abs/2310.15372">EpiK-Eval</a></span> benchmark highlights a significant limitation of Large Language Models (LLMs): they do not inherently learn all dependencies present in their training data, even though such dependencies are crucial for effective problem-solving. This realization underscores the need for continued research into this phenomenon. More importantly, it calls for the development of innovative methods to address this fundamental challenge. Successfully consolidating the knowledge within LLMs could greatly enhance their utility across various scales and applications.
        <div id="slide33-34-container">
            <div id="slide33background" class="slide33-34"><img src="/blog_posts/epik-eval/images/slide33B.svg"/></div>
            <div id="slide33" class="slide33-34"><img src="/blog_posts/epik-eval/images/slide33.svg"/></div>
            <div id="slide34" class="slide33-34"><img src="/blog_posts/epik-eval/images/slide34.svg"/></div>
        </div>
        For a comprehensive understanding of our findings and methodology, we encourage delving into the full <span class="in-text-paper-link-container"><a class="in-text-paper-link" href="https://arxiv.org/abs/2310.15372">EpiK-Eval</a></span> paper. For those interested in hands-on exploration or further research, our code is available on <span class="in-text-paper-link-container"><a class="in-text-paper-link" href="https://github.com/chandar-lab/EpiK-Eval">Github</a></span>. We encourage collaboration and innovation in this exciting field and look forward to seeing how the community advances these concepts.
        <div id="small-screen-author-list">
            <div id="small-author-list-row1">
                <span id="small-author-gabriele"><a id="author-link" href="https://gabprato.github.io/">Gabriele Prato</a></span>
                <span id="small-author-jerry"><a id="author-link" href="https://jhuang265.github.io/">Jerry Huang</a></span>
            </div>
            <div id="small-author-list-row2">
                <span id="small-author-prasanna"><a id="author-link" href="https://cs.mcgill.ca/~pparth2/">Prasannna Parthasarathi</a></span>
                <span id="small-author-shagun"><a id="author-link" href="https://shagunsodhani.com/">Shagun Sodhani</a></span>
            </div>
            <div id="small-author-list-row3">
                <span id="small-author-sarath"><a id="author-link" href="http://sarathchandar.in/">Sarath Chandar</a></span>
            </div>
        </div>
        <div id="large-screen-author-list">
            <div id="large-author-list-row1">
                <span id="large-author-gabriele"><a id="author-link" href="https://gabprato.github.io/">Gabriele Prato</a></span>
                <span id="large-author-jerry"><a id="author-link" href="https://jhuang265.github.io/">Jerry Huang</a></span>
                <span id="large-author-prasanna"><a id="author-link" href="https://cs.mcgill.ca/~pparth2/">Prasannna Parthasarathi</a></span>
            </div>
            <div id="large-author-list-row2">
                <span id="large-author-shagun"><a id="author-link" href="https://shagunsodhani.com/">Shagun Sodhani</a></span>
                <span id="large-author-sarath"><a id="author-link" href="http://sarathchandar.in/">Sarath Chandar</a></span>
            </div>
        </div>
    </div>

    <div class="bibtex">
        <div class="bibtex-header">BibTeX</div>
        <div class="bibtex-entry-container">
            <div class="copy-text-icon-container">
                <img src="/blog_posts/epik-eval/images/copy_text_icon.png" class="copy-text-icon">
                <img src="/blog_posts/epik-eval/images/copy_text_icon_hover.png" class="copy-text-icon-hover">
            </div>
            <div class="bibtex-entry" id="bibtex-epik-eval">
                @ARTICLE&#123;2023arXiv231015372P,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;author = &#123;&#123;Prato&#125;, Gabriele and &#123;Huang&#125;, Jerry and &#123;Parthasarathi&#125;, Prasannna and &#123;Sodhani&#125;, Shagun and &#123;Chandar&#125;, Sarath&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title = "&#123;EpiK-Eval: Evaluation for Language Models as Epistemic Models&#125;",<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;journal = &#123;arXiv e-prints&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keywords = &#123;Computer Science - Computation and Language, Computer Science - Artificial Intelligence&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;year = 2023,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;month = oct,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;eid = &#123;arXiv:2310.15372&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pages = &#123;arXiv:2310.15372&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;doi = &#123;10.48550/arXiv.2310.15372&#125;,<br/>
                archivePrefix = &#123;arXiv&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;eprint = &#123;2310.15372&#125;,<br/>
                &nbsp;primaryClass = &#123;cs.CL&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adsurl = &#123;https://ui.adsabs.harvard.edu/abs/2023arXiv231015372P&#125;,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adsnote = &#123;Provided by the SAO/NASA Astrophysics Data System&#125;<br/>
                &#125;<br/><br/><br/>
            </div>
        </div>
    </div>
    <script src="/blog_posts/epik-eval/script.js"></script>
</body>
</html>
